#!/usr/bin/env python3
"""
åˆå¹¶å¤šä¸ª GPU ç”Ÿæˆçš„éƒ¨åˆ†æ•°æ®æ–‡ä»¶
"""

import json
import glob
from pathlib import Path

def merge_distilled_data(pattern="pangu_distilled_part_*.json", output="pangu_self_distilled_data.json"):
    """åˆå¹¶æ‰€æœ‰éƒ¨åˆ†æ–‡ä»¶"""
    
    part_files = sorted(glob.glob(pattern))
    
    if not part_files:
        print(f"âŒ No files found matching: {pattern}")
        return
    
    print(f"Found {len(part_files)} part files:")
    for f in part_files:
        print(f"  - {f}")
    
    all_data = []
    
    for part_file in part_files:
        with open(part_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            all_data.extend(data)
            print(f"  Loaded {len(data)} samples from {part_file}")
    
    # ä¿å­˜åˆå¹¶ç»“æœ
    with open(output, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Merged {len(all_data)} total samples")
    print(f"   Output: {output}")
    
    # ç»Ÿè®¡
    print(f"\nğŸ“Š Statistics:")
    print(f"   Total conversations: {len(all_data)}")
    
    total_tokens = 0
    for item in all_data:
        for conv in item.get("conversations", []):
            if conv.get("from") == "gpt":
                total_tokens += len(conv.get("value", "").split())
    
    avg_tokens = total_tokens / len(all_data) if all_data else 0
    print(f"   Avg tokens per response: {avg_tokens:.1f}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--pattern", default="pangu_distilled_part_*.json")
    parser.add_argument("--output", default="pangu_self_distilled_data.json")
    args = parser.parse_args()
    
    merge_distilled_data(args.pattern, args.output)
